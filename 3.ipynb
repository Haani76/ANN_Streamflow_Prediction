{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17109bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate models with different configurations\n",
    "for neurons_per_layer, config_label in configurations:\n",
    "    for activation_function, act_label in activations:\n",
    "        for optimizer, opt_label in optimizers:\n",
    "            print(f\"Training model with configuration: {neurons_per_layer}, activation: {act_label}, optimizer: {opt_label}\")\n",
    "            \n",
    "            # Build and train the model\n",
    "            nn_model = build_nn_model(neurons_per_layer, activation_function, optimizer)\n",
    "            history = nn_model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose=2, \n",
    "                                   callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True), \n",
    "                                              model_checkpoint_callback, csv_logger])\n",
    "\n",
    "            # Normalize the loss values\n",
    "            scaler_loss = MinMaxScaler(feature_range=(0, 1))\n",
    "            normalized_train_loss = scaler_loss.fit_transform(np.array(history.history['loss']).reshape(-1, 1)).flatten()\n",
    "            normalized_val_loss = scaler_loss.transform(np.array(history.history['val_loss']).reshape(-1, 1)).flatten()\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_train_pred = nn_model.predict(X_train)\n",
    "            y_test_pred = nn_model.predict(X_test)\n",
    "\n",
    "            # Inverse transform to get actual values\n",
    "            y_train_pred_actual = scaler_y.inverse_transform(y_train_pred).flatten()\n",
    "            y_test_pred_actual = scaler_y.inverse_transform(y_test_pred).flatten()\n",
    "            y_test_actual = scaler_y.inverse_transform(y_test).flatten()\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            r2_train = r2_score(train_data['q'], y_train_pred_actual)\n",
    "            r2_test = r2_score(test_data['q'], y_test_pred_actual)\n",
    "            rmse_train = np.sqrt(mean_squared_error(train_data['q'], y_train_pred_actual))\n",
    "            rmse_test = np.sqrt(mean_squared_error(test_data['q'], y_test_pred_actual))\n",
    "            mae_train = mean_absolute_error(train_data['q'], y_train_pred_actual)\n",
    "            mae_test = mean_absolute_error(test_data['q'], y_test_pred_actual)\n",
    "            rme_train = np.sqrt(np.mean((y_train_pred_actual - train_data['q']) ** 2)) / np.mean(train_data['q'])\n",
    "            rme_test = np.sqrt(np.mean((y_test_pred_actual - test_data['q']) ** 2)) / np.mean(test_data['q'])\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                'configuration': config_label,\n",
    "                'activation': act_label,\n",
    "                'optimizer': opt_label,\n",
    "                'r2_train': r2_train,\n",
    "                'r2_test': r2_test,\n",
    "                'rmse_train': rmse_train,\n",
    "                'rmse_test': rmse_test,\n",
    "                'mae_train': mae_train,\n",
    "                'mae_test': mae_test,\n",
    "                'rme_train': rme_train,\n",
    "                'rme_test': rme_test\n",
    "            })\n",
    "\n",
    "\n",
    "            # Set Times New Roman before plotting\n",
    "            plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "            sns.set(style=\"white\", font=\"Times New Roman\")  # or style=\"ticks\" for a cleaner look\n",
    "\n",
    "\n",
    "        # Set fixed y-axis limits (adjust these based on your data)\n",
    "            y_min, y_max = -1, 1  # Example fixed range; adjust as needed\n",
    "\n",
    "            # Plot normalized training vs testing loss curves\n",
    "            plt.figure(figsize=(14, 6), dpi=300)  \n",
    "            plt.plot(normalized_train_loss, color='green', linestyle='--', linewidth=5)  # Training Loss\n",
    "            plt.plot(normalized_val_loss, color='purple', linewidth=5)  # Validation Loss\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Customize ticks and labels\n",
    "            plt.xticks(fontsize=40, fontweight='bold')\n",
    "            plt.yticks(fontsize=40, fontweight='bold')\n",
    "            plt.gca().tick_params(axis='both', which='major', pad=20)  # Further control over tick label spacing\n",
    "\n",
    "            # Label Axes with Padding\n",
    "            plt.xlabel('Epochs', fontsize=40, fontweight='bold', labelpad=15)  # Add more padding to x-axis label\n",
    "            plt.ylabel('Loss', fontsize=40, fontweight='bold', labelpad=10) \n",
    "\n",
    "            # Set fixed y-axis limits\n",
    "            plt.ylim(y_min, y_max)\n",
    "\n",
    "            # Set fixed y-ticks (customize these as per your data)\n",
    "            plt.yticks([y_min, (y_min + y_max) / 2, y_max], fontsize=40, fontweight='bold') \n",
    "\n",
    "            # Set x-axis limits from 0 to 49 (for 50 epochs)\n",
    "            plt.xlim(0, 49)\n",
    "\n",
    "            # Custom x-ticks for epochs\n",
    "            plt.xticks([0, 20, 40], fontsize=40, fontweight='bold')  # First, middle, last epochs\n",
    "\n",
    "\n",
    "            plt.show()  # Removed legend\n",
    "\n",
    "\n",
    "\n",
    "           # Filter test data for actual vs predicted plot (after 2018)\n",
    "            mask = test_data['date'] >= '2018-01-01'\n",
    "            test_dates_filtered = test_data[mask]['date']\n",
    "            y_test_actual_filtered = y_test_actual[mask]\n",
    "            y_test_pred_actual_filtered = y_test_pred_actual[mask]\n",
    "\n",
    "\n",
    "            # Set Times New Roman before plotting\n",
    "            plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "            sns.set(style=\"white\", font=\"Times New Roman\")\n",
    "\n",
    "\n",
    "            # Plot actual vs predicted discharge values\n",
    "            plt.figure(figsize=(14, 6), dpi=300)  \n",
    "            plt.plot(test_dates_filtered, y_test_actual_filtered, color='black', linewidth=5)  # Actual\n",
    "            plt.plot(test_dates_filtered, y_test_pred_actual_filtered, linestyle='--', color='red', linewidth=5)  # Predicted\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Customize x-ticks: Display only alternate years\n",
    "            plt.xticks(fontsize=40, fontweight='bold')\n",
    "            plt.gca().tick_params(axis='both', which='major', pad=10)  # Further control over tick label spacing\n",
    "\n",
    "            # Set y-ticks to specific values\n",
    "            plt.yticks([0, 3000, 6000], fontsize=40, fontweight='bold')\n",
    "            plt.gca().tick_params(axis='both', which='major', pad=10)  # Further control over tick label spacing\n",
    "\n",
    "            # Custom x-ticks: Display only alternate years\n",
    "            distinct_years = test_dates_filtered.dt.year.drop_duplicates().sort_values()\n",
    "            alternate_years = distinct_years[::2]  # Select every second year\n",
    "\n",
    "            plt.xticks(\n",
    "                [test_dates_filtered[test_dates_filtered.dt.year == year].iloc[0] for year in alternate_years],\n",
    "                [str(year) for year in alternate_years],\n",
    "                fontsize=40,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "            # Set y-axis label only\n",
    "            plt.xlabel('Date', fontsize=40, fontweight='bold', labelpad=15)\n",
    "            plt.ylabel('Discharge', fontsize=40, fontweight='bold', labelpad=10)\n",
    "\n",
    "            plt.show()  # Removed legend and title"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
